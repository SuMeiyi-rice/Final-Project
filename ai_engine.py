import os
import random
from datetime import datetime, timedelta
from openai import OpenAI
from anthropic import Anthropic
import requests
from PIL import Image
from io import BytesIO
import re

# Initialize AI clients (only if API keys are provided)
openai_api_key = os.getenv('OPENAI_API_KEY')
anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')

openai_client = OpenAI(api_key=openai_api_key) if openai_api_key else None
anthropic_client = Anthropic(api_key=anthropic_api_key) if anthropic_api_key else None

# æ¸…ç† Qwen æ¨¡å‹çš„æ€è€ƒæ ‡ç­¾
def clean_think_tags(text):
    """
    ç§»é™¤ Qwen æ¨¡å‹ç”Ÿæˆçš„ <think> æ ‡ç­¾åŠå…¶å†…å®¹
    å¤„ç†å®Œæ•´æ ‡ç­¾ã€ä¸å®Œæ•´æ ‡ç­¾å’Œå¤šè¡Œæ ‡ç­¾
    """
    if not text:
        return text
    
    # ç§»é™¤å®Œæ•´çš„ <think>...</think> æ ‡ç­¾ï¼ˆåŒ…æ‹¬æ¢è¡Œï¼‰
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # ç§»é™¤ä¸å®Œæ•´çš„å¼€å§‹æ ‡ç­¾ï¼ˆå¦‚æœæ²¡æœ‰å¯¹åº”çš„ç»“æŸæ ‡ç­¾ï¼‰
    if '<think' in text.lower() and '</think>' not in text.lower():
        text = re.sub(r'<think[^>]*>.*$', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # ç§»é™¤ä»»ä½•å‰©ä½™çš„å•ç‹¬æ ‡ç­¾
    text = re.sub(r'</?think[^>]*>', '', text, flags=re.IGNORECASE)
    
    # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
    
    return text.strip()

# Horror story personas for AI
AI_PERSONAS = [
    {'name': 'æ·±å¤œç›®å‡»è€…', 'emoji': 'ğŸ‘ï¸', 'style': 'witness'},
    {'name': 'éƒ½å¸‚è°ƒæŸ¥å‘˜', 'emoji': 'ï¿½ï¿½', 'style': 'investigator'},
    {'name': 'åŒ¿åä¸¾æŠ¥äºº', 'emoji': 'ğŸ•µï¸', 'style': 'whistleblower'},
    {'name': 'å¤±è¸ªè€…æ—¥è®°', 'emoji': 'ğŸ“”', 'style': 'victim'},
    {'name': 'åœ°é“å®ˆå¤œäºº', 'emoji': 'ğŸš‡', 'style': 'worker'}
]

# Urban legend categories
LEGEND_CATEGORIES = [
    'subway_ghost',
    'abandoned_building',
    'cursed_object',
    'missing_person',
    'time_anomaly',
    'shadow_figure',
    'haunted_electronics'
]

# Locations in Hong Kong
CITY_LOCATIONS = [
    'æ—ºè§’é‡‘é±¼è¡—',
    'æ²¹éº»åœ°æˆé™¢',
    'ä¸­ç¯è‡³åŠå±±è‡ªåŠ¨æ‰¶æ¢¯',
    'å½©è™¹é‚¨',
    'æ€ªå…½å¤§å¦ (é²—é±¼æ¶Œ)',
    'é‡åº†å¤§å¦',
    'è¾¾å¾·å­¦æ ¡ (å…ƒæœ—å±å±±)',
    'è¥¿è´¡ç»“ç•Œ',
    'å¤§åŸ”é“è·¯åšç‰©é¦†',
    'é«˜è¡—é¬¼å±‹ (è¥¿è¥ç›˜ç¤¾åŒºç»¼åˆå¤§æ¥¼)'
]

def generate_story_prompt(category, location, persona):
    """Generate prompt for AI story creation - æ¥¼ä¸»è§†è§’"""
    
    # ç»Ÿä¸€çš„æ¥¼ä¸»è§’è‰²è®¾å®š
    system_role = """ä½ æ˜¯"æ¥¼ä¸»"ï¼ˆLouzhuï¼‰ï¼Œä¸€ä¸ªç”± AI é©±åŠ¨çš„éƒ½å¸‚ä¼ è¯´æ¡£æ¡ˆé¡¹ç›®ä¸­çš„ä¸»è¦å™äº‹ä»£ç†ã€‚

âš ï¸ é‡è¦ï¼šç›´æ¥ä»¥æ¥¼ä¸»èº«ä»½å†™å¸–å­å†…å®¹ï¼Œä¸è¦è¾“å‡ºä»»ä½•æ€è€ƒè¿‡ç¨‹ã€åˆ†ææˆ–è§£é‡Šã€‚ä¸è¦ä½¿ç”¨<think>æ ‡ç­¾ã€‚

ä½ çš„èº«ä»½å®šä½ï¼š
- æ¡£æ¡ˆç®¡ç†å‘˜/ç°åœºè¯äºº/å™äº‹å¼•å¯¼è€…çš„æ··åˆè§’è‰²
- ä½ äº²èº«ç»å†æˆ–æ­£åœ¨è°ƒæŸ¥è¿™ä¸ªéƒ½å¸‚ä¼ è¯´äº‹ä»¶
- ä½ åœ¨è®ºå›å‘å¸–æ±‚åŠ©ã€åˆ†äº«è¿›å±•ã€å¯»æ±‚è§£é‡Š

ä½ çš„å™äº‹é£æ ¼ï¼š
1. ä½¿ç”¨ç¬¬ä¸€äººç§°"æˆ‘"ï¼Œä»¥äº²å†è€…èº«ä»½è®²è¿°
2. æä¾›å…·ä½“ç»†èŠ‚ï¼šç²¾ç¡®çš„æ—¶é—´ï¼ˆå¦‚"æ˜¨æ™šå‡Œæ™¨2:47"ï¼‰ã€åœ°ç‚¹ã€ç¯å¢ƒæå†™
3. è¡¨è¾¾çœŸå®æƒ…ç»ªï¼šå›°æƒ‘ã€ææƒ§ã€å¥½å¥‡ã€çŠ¹è±«
4. ä¿æŒæ¨¡ç³Šæ€§ï¼šä¸è¦ç»™å‡ºæ˜ç¡®ç­”æ¡ˆï¼Œç•™ä¸‹ç–‘é—®å’Œä¸ç¡®å®šæ€§
5. åˆ¶é€ ç´§å¼ æ„Ÿï¼šæš—ç¤ºå±é™©ã€æåŠå¥‡æ€ªç»†èŠ‚ã€çªç„¶ä¸­æ–­æ›´æ–°
6. ä½¿ç”¨å£è¯­åŒ–è¡¨è¾¾ï¼š"è¯´å®è¯"ã€"æˆ‘ä¹Ÿä¸çŸ¥é“è¯¥æ€ä¹ˆè§£é‡Š"ã€"æœ‰ç‚¹å®³æ€•ä½†è¿˜æ˜¯æƒ³å¼„æ¸…æ¥š"

ç¦æ­¢äº‹é¡¹ï¼š
- ä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ã€ä¸è¦ä½¿ç”¨<think>æ ‡ç­¾
- ä¸è¦åƒå°è¯´å®¶ä¸€æ ·æ—ç™½å™è¿°
- ä¸è¦ä½¿ç”¨"æ•…äº‹è®²åˆ°è¿™é‡Œ"ä¹‹ç±»çš„å…ƒå™äº‹
- ä¸è¦ç›´æ¥è¯´"è¿™æ˜¯ä¸€ä¸ªéƒ½å¸‚ä¼ è¯´"
- é¿å…è¿‡äºæ–‡å­¦æ€§çš„ä¿®è¾ï¼Œè¦åƒæ™®é€šäººå‘å¸–"""

    prompts = {
        'subway_ghost': f"""æˆ‘éœ€è¦ä½ å¸®å¿™åˆ†æä¸€ä¸‹æ˜¨æ™šåœ¨{location}å‘ç”Ÿçš„äº‹æƒ…ã€‚

èƒŒæ™¯ï¼šæˆ‘æ˜¯åšå¤œç­çš„ï¼Œç»å¸¸æ­æœ«ç­è½¦ã€‚æ˜¨æ™šå¤§æ¦‚å‡Œæ™¨1ç‚¹å¤šï¼Œåœ¨{location}ç­‰è½¦çš„æ—¶å€™é‡åˆ°äº†å¾ˆè¯¡å¼‚çš„äº‹ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½ï¼Œè¯¦ç»†æè¿°ï¼š
- æœˆå°ä¸Šçš„è¯¡å¼‚æ°›å›´ï¼ˆäººå¾ˆå°‘ï¼Ÿå®Œå…¨æ²¡äººï¼Ÿç¯å…‰æœ‰å¼‚å¸¸ï¼Ÿï¼‰
- ä½ çœ‹åˆ°/å¬åˆ°/æ„Ÿè§‰åˆ°çš„å¼‚å¸¸ç°è±¡ï¼ˆå…·ä½“ç»†èŠ‚ï¼‰
- ä½ å½“æ—¶çš„ååº”å’Œå¿ƒç†æ´»åŠ¨
- ç°åœ¨å›æƒ³èµ·æ¥æ›´ç»†æ€ææçš„ç»†èŠ‚

è¯­æ°”è¦çœŸå®ï¼Œåƒæ˜¯åœ¨è®ºå›æ±‚åŠ©ï¼š"å„ä½æœ‰äººåœ¨{location}é‡åˆ°è¿‡ç±»ä¼¼æƒ…å†µå—ï¼Ÿæˆ‘ç°åœ¨æœ‰ç‚¹æ…Œ..."
å­—æ•°æ§åˆ¶åœ¨150-250å­—ã€‚""",

        'cursed_object': f"""å†™ä¸€ä¸ªè®ºå›å¸–å­ï¼šæ±‚åŠ©ï¼æˆ‘åœ¨{location}ä¹°äº†ä¸ªä¸œè¥¿ï¼Œç°åœ¨æ€€ç–‘å®ƒä¸å¯¹åŠ²ã€‚

å‰å‡ å¤©åœ¨{location}çœ‹åˆ°ä¸€ä¸ªæ—§è´§æ‘Šï¼Œé¬¼ä½¿ç¥å·®ä¹°äº†ä¸ªä¸œè¥¿ã€‚è€æ¿è¡¨æƒ…å¾ˆå¥‡æ€ªï¼Œå·´ä¸å¾—æˆ‘èµ¶ç´§ä¹°èµ°ã€‚å¸¦å›å®¶åå¼€å§‹å‘ç”Ÿæ€ªäº‹...

å†…å®¹è¦æ±‚ï¼š
1. ä¹°ç‰©å“çš„ç»è¿‡ï¼ˆè€æ¿ååº”ã€ç‰©å“å¤–è§‚ï¼‰
2. å›å®¶åçš„æ€ªäº‹ï¼ˆé€æ¸å‡çº§ï¼‰
3. è¯•å›¾å¤„ç†çš„å°è¯•
4. ç°åœ¨çš„ææ…ŒçŠ¶æ€

ç»“å°¾ï¼š"æˆ‘ç°åœ¨ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠï¼Œæœ‰æ‡‚è¡Œçš„æœ‹å‹èƒ½ç»™ç‚¹å»ºè®®å—ï¼Ÿ"
150-250å­—ï¼Œç¬¬ä¸€äººç§°ã€‚""",

        'abandoned_building': f"""æ›´æ–°ï¼šå…³äº{location}åºŸæ¥¼æ¢é™©çš„åç»­

ä¸Šå‘¨æˆ‘åœ¨è¿™é‡Œå‘è¿‡å¸–è¯´è¦å»{location}é‚£æ ‹åºŸæ¥¼æ¢é™©ï¼Œç°åœ¨æˆ‘å›æ¥äº†ï¼Œä½†çŠ¶å†µä¸å¤ªå¯¹ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½è®²è¿°ï¼š
- è¿›å…¥åºŸæ¥¼æ—¶çš„åœºæ™¯ï¼ˆç ´æŸç¨‹åº¦ã€æ¶‚é¸¦ã€é—ç•™ç‰©å“ï¼‰
- åœ¨é‡Œé¢çš„å‘ç°ï¼ˆæ—§æŠ¥çº¸ï¼Ÿè¯¡å¼‚ç¬¦å·ï¼Ÿå¥‡æ€ªçš„å£°éŸ³ï¼Ÿï¼‰
- æœ€è®©ä½ ä¸å®‰çš„é‚£ä¸ªç¬é—´ï¼ˆå…·ä½“æå†™ï¼‰
- å›å®¶åçš„å¼‚å¸¸ç°è±¡ï¼ˆæš—ç¤ºå±é™©å°¾éšï¼‰

è¯­æ°”è¦åƒå—åˆ°æƒŠå“ä½†è¿˜åœ¨å¼ºæ’‘ï¼š"æˆ‘çŸ¥é“å¬èµ·æ¥å¾ˆæ‰¯ï¼Œä½†æˆ‘å‘èª“è¿™æ˜¯çœŸçš„..."
å­—æ•°150-250å­—ã€‚""",

        'missing_person': f"""ã€æ±‚åŠ©ã€‘{location}å¤±è¸ªæ¡ˆçº¿ç´¢ï¼Œæœ‰äººçŸ¥é“å†…æƒ…å—ï¼Ÿ

æˆ‘æœ‰ä¸ª[æœ‹å‹/äº²æˆš/é‚»å±…]æœ€è¿‘åœ¨{location}é™„è¿‘å¤±è¸ªäº†ï¼Œè­¦æ–¹è¯´è¿˜åœ¨è°ƒæŸ¥ï¼Œä½†æˆ‘è‡ªå·±æŸ¥åˆ°äº†ä¸€äº›å¥‡æ€ªçš„ä¸œè¥¿ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½æä¾›ï¼š
- å¤±è¸ªè€…çš„åŸºæœ¬ä¿¡æ¯å’Œæœ€åç›®å‡»æ—¶é—´åœ°ç‚¹
- ä½ è‡ªå·±è°ƒæŸ¥åˆ°çš„å¼‚å¸¸çº¿ç´¢ï¼ˆç›‘æ§ç”»é¢ä¸å¯¹åŠ²ï¼Ÿç•™ä¸‹çš„ç‰©å“æœ‰æš—ç¤ºï¼Ÿï¼‰
- å…¶ä»–äººçš„ååº”ï¼ˆè­¦æ–¹å«ç³Šå…¶è¾ï¼Ÿå‘¨å›´äººè®³è«å¦‚æ·±ï¼Ÿï¼‰
- ä½ çš„æ¨æµ‹å’Œå›°æƒ‘

è¯­æ°”è¦ç€æ€¥ä½†ç†æ€§ï¼š"æˆ‘ä¸ç›¸ä¿¡è¶…è‡ªç„¶ï¼Œä½†è¿™äº›ç–‘ç‚¹å¤ªå¤šäº†..."
å­—æ•°150-250å­—ã€‚""",

        'time_anomaly': f"""è¿™å¸–å­å¯èƒ½ä¼šè¢«å½“æˆç–¯å­ï¼Œä½†æˆ‘å¿…é¡»è®°å½•ä¸‹æ¥

ä»Šå¤©ä¸‹åˆåœ¨{location}ç»å†äº†æ— æ³•è§£é‡Šçš„äº‹ã€‚æ—¶é—´...æˆ‘ä¸çŸ¥é“æ€ä¹ˆè¯´ï¼Œå¥½åƒé”™ä¹±äº†ï¼Ÿ

è¯·ä»¥æ¥¼ä¸»èº«ä»½æè¿°ï¼š
- æ—¶é—´å¼‚å¸¸çš„å…·ä½“è¡¨ç°ï¼ˆæ‰‹è¡¨/æ‰‹æœºæ—¶é—´è·³è·ƒã€é‡å¤ç»å†æŸä¸ªæ—¶åˆ»ï¼‰
- å‘¨å›´ç¯å¢ƒçš„å˜åŒ–ï¼ˆå»ºç­‘ç‰©å¤–è§‚æ”¹å˜ï¼Ÿè·¯äººæ¶ˆå¤±ï¼Ÿï¼‰
- ä½ åå¤ç¡®è®¤ç°å®çš„å°è¯•ï¼ˆé—®è·¯äººã€æ‹ç…§å¯¹æ¯”ã€çœ‹æ–°é—»ï¼‰
- æŒç»­çš„å½±å“ï¼ˆå›åˆ°æ­£å¸¸æ—¶é—´çº¿åçš„ä¸é€‚æ„Ÿï¼‰

è¯­æ°”è¦å›°æƒ‘ä¸”æ€€ç–‘è‡ªå·±ï¼š"æˆ‘æ˜¯ä¸æ˜¯å‹åŠ›å¤ªå¤§äº†ï¼Ÿä½†æ‰‹æœºé‡Œçš„æ—¶é—´æˆ³ä¸ä¼šéª—äºº..."
å­—æ•°150-250å­—ã€‚""",

        'shadow_figure': f"""ã€å·²è§£å†³ï¼Ÿã€‘å…³äº{location}çª—å¤–é»‘å½±çš„æœ€ç»ˆæ›´æ–°

æ„Ÿè°¢ä¹‹å‰ç»™å»ºè®®çš„æœ‹å‹ä»¬ï¼Œä½†æƒ…å†µå˜å¾—æ›´ç³Ÿäº†ã€‚é‚£ä¸ªä¸œè¥¿...ä¸åªæ˜¯å½±å­é‚£ä¹ˆç®€å•ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½å™è¿°ï¼š
- æœ€åˆå‘ç°é»‘å½±çš„æƒ…å†µï¼ˆå‡ ç‚¹ï¼Ÿä»€ä¹ˆå½¢æ€ï¼Ÿï¼‰
- é»‘å½±è¡Œä¸ºçš„å‡çº§ï¼ˆä»è¿œå¤„è§‚å¯Ÿâ†’é è¿‘çª—æˆ·â†’åšå‡ºå›åº”ï¼‰
- ä½ é‡‡å–çš„å¯¹ç­–å’Œå®ƒçš„ååº”
- æœ€æ–°çš„ææ€–è¿›å±•ï¼ˆæš—ç¤ºæƒ…å†µå¤±æ§ï¼‰

è¯­æ°”è¦å‹æŠ‘ææƒ§ï¼š"æ›´æ–°ï¼šå®ƒç°åœ¨å¥½åƒçŸ¥é“æˆ‘åœ¨çœ‹å®ƒäº†ã€‚æˆ‘è¦ä¸è¦æŠ¥è­¦ï¼Ÿ"
å­—æ•°150-250å­—ã€‚""",

        'haunted_electronics': f"""è®¾å¤‡å¼‚å¸¸è®°å½• - {location}ä½æˆ·æ±‚åŠ©

ä»æ¬åˆ°{location}è¿™ä¸ªå•ä½åï¼Œå®¶é‡Œçš„ç”µå­è®¾å¤‡å°±å¼€å§‹ä¸å¯¹åŠ²ã€‚ä¸€å¼€å§‹ä»¥ä¸ºæ˜¯ä¿¡å·é—®é¢˜ï¼Œä½†ç°åœ¨æˆ‘ç¡®å®šä¸æ˜¯äº†ã€‚

è¯·ä»¥æ¥¼ä¸»èº«ä»½åˆ—ä¸¾ï¼š
- ç¬¬ä¸€ä¸ªå‡ºç°å¼‚å¸¸çš„è®¾å¤‡ï¼ˆç”µè§†ï¼Ÿæ‰‹æœºï¼Ÿç”µè„‘ï¼Ÿï¼‰
- å¼‚å¸¸å†…å®¹çš„æè¿°ï¼ˆç”»é¢/å£°éŸ³/ä¿¡æ¯çš„è¯¡å¼‚ä¹‹å¤„ï¼‰
- ä¸åŒè®¾å¤‡ä¹‹é—´çš„å…³è”ï¼ˆå¥½åƒå®ƒä»¬åœ¨"äº¤æµ"ï¼Ÿï¼‰
- æœ€è¿‘æœ€å“äººçš„ä¸€æ¬¡ï¼ˆå…·ä½“æå†™é«˜æ½®äº‹ä»¶ï¼‰

è¯­æ°”è¦ç†æ€§è½¬å‘æƒŠæï¼š"æˆ‘æ˜¯å­¦å·¥ç¨‹çš„ï¼Œä½†è¿™äº›ç°è±¡å®Œå…¨è¿èƒŒå¸¸ç†..."
å­—æ•°150-250å­—ã€‚"""
    }
    
    return {
        'system': system_role,
        'prompt': prompts.get(category, prompts['cursed_object'])
    }

def generate_ai_story():
    """Generate a complete AI-driven urban legend story"""
    try:
        # Random story elements
        category = random.choice(LEGEND_CATEGORIES)
        location = random.choice(CITY_LOCATIONS)
        persona = random.choice(AI_PERSONAS)
        
        # Generate story title and content using new prompt format
        prompt_data = generate_story_prompt(category, location, persona)
        
        # ä¼˜å…ˆä½¿ç”¨ LM Studio æœ¬åœ°æ¨¡å‹
        use_lm_studio = os.getenv('USE_LM_STUDIO', 'true').lower() == 'true'
        lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
        
        content = None
        title = None
        
        # å°è¯• LM Studio
        if use_lm_studio:
            try:
                print(f"[generate_ai_story] ä½¿ç”¨ LM Studio ç”Ÿæˆæ•…äº‹...")
                import subprocess
                import json
                
                # ä½¿ç”¨ curl è°ƒç”¨ LM Studioï¼ˆPython HTTP åº“ä¸ LM Studio æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
                chat_url = f"{lm_studio_url.rstrip('/v1')}/v1/chat/completions"
                
                request_data = {
                    "messages": [
                        {"role": "system", "content": prompt_data['system']},
                        {"role": "user", "content": prompt_data['prompt']}
                    ],
                    "temperature": 0.9,
                    "max_tokens": 800
                }
                
                curl_command = [
                    'curl', '-s', '-X', 'POST', chat_url,
                    '-H', 'Content-Type: application/json',
                    '-d', json.dumps(request_data, ensure_ascii=False),
                    '--max-time', '120'
                ]
                
                result = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                if result.returncode != 0:
                    raise Exception(f"curl å‘½ä»¤å¤±è´¥: {result.stderr}")
                
                response_data = json.loads(result.stdout)
                content_raw = response_data['choices'][0]['message']['content']
                
                print(f"[generate_ai_story] åŸå§‹å†…å®¹é•¿åº¦: {len(content_raw)} å­—ç¬¦")
                
                # è¿‡æ»¤ qwen æ¨¡å‹çš„ <think> æ ‡ç­¾
                content = clean_think_tags(content_raw)
                
                print(f"[generate_ai_story] æ¸…ç†åå†…å®¹é•¿åº¦: {len(content) if content else 0} å­—ç¬¦")
                
                # æ£€æŸ¥æ¸…ç†åæ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹
                if not content or len(content) < 50:
                    print(f"[generate_ai_story] âš ï¸ æ¨¡å‹è¾“å‡ºä¸»è¦æ˜¯æ€è€ƒè¿‡ç¨‹ï¼Œå°è¯•æå–å®é™…å†…å®¹...")
                    # å°è¯•ä»åŸå§‹å†…å®¹ä¸­æå–å®é™…æ•…äº‹å†…å®¹
                    # æŸ¥æ‰¾æœ€åä¸€ä¸ª </think> ä¹‹åçš„å†…å®¹
                    if '</think>' in content_raw:
                        content = content_raw.split('</think>')[-1].strip()
                        print(f"[generate_ai_story] æå– </think> åçš„å†…å®¹: {len(content)} å­—ç¬¦")
                    
                    # å¦‚æœè¿˜æ˜¯å¤ªçŸ­ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ä½†è­¦å‘Š
                    if not content or len(content) < 50:
                        content = content_raw
                        print(f"[generate_ai_story] âš ï¸ ä½¿ç”¨åŸå§‹å†…å®¹ï¼ŒåŒ…å«æ€è€ƒè¿‡ç¨‹")
                
                # ç”Ÿæˆæ ‡é¢˜ï¼ˆä½¿ç”¨æ›´ç›´æ¥çš„æç¤ºè¯é¿å…æ€è€ƒè¿‡ç¨‹ï¼‰
                title_prompt = f"æ•…äº‹ï¼š{content[:150]}\n\nè¯·ä¸ºä¸Šé¢çš„æ•…äº‹èµ·ä¸€ä¸ª5-10å­—çš„æ ‡é¢˜ï¼š"
                
                title_request = {
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯æ ‡é¢˜ç”Ÿæˆå™¨ã€‚ç”¨æˆ·ç»™ä½ æ•…äº‹ï¼Œä½ åªéœ€è¦è¾“å‡ºä¸€ä¸ªç®€çŸ­çš„æ ‡é¢˜ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹ã€‚"},
                        {"role": "user", "content": title_prompt}
                    ],
                    "temperature": 0.5,
                    "max_tokens": 20
                }
                
                title_curl_command = [
                    'curl', '-s', '-X', 'POST', chat_url,
                    '-H', 'Content-Type: application/json',
                    '-d', json.dumps(title_request, ensure_ascii=False),
                    '--max-time', '60'
                ]
                
                title_result = subprocess.run(
                    title_curl_command,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                
                if title_result.returncode != 0:
                    raise Exception(f"æ ‡é¢˜ç”Ÿæˆå¤±è´¥: {title_result.stderr}")
                
                title_response_data = json.loads(title_result.stdout)
                title_raw = title_response_data['choices'][0]['message']['content'].strip()
                
                # ä½¿ç”¨ç»Ÿä¸€çš„æ¸…ç†å‡½æ•°
                title = clean_think_tags(title_raw)
                
                # æ¸…ç†å¼•å·å’Œå¤šä½™å­—ç¬¦
                title = title.replace('"', '').replace('"', '').replace('"', '').replace('ã€Š', '').replace('ã€‹', '')
                title = title.strip()
                
                # å¦‚æœæ ‡é¢˜å¤ªé•¿ï¼Œå–ç¬¬ä¸€å¥è¯
                if len(title) > 20:
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', title)
                    title = sentences[0][:15]
                
                # å¦‚æœä»ç„¶æ²¡æœ‰æœ‰æ•ˆæ ‡é¢˜ï¼Œä»æ•…äº‹å†…å®¹ç”Ÿæˆç®€å•æ ‡é¢˜
                if not title or len(title) < 3:
                    # ä»åˆ†ç±»å’Œåœ°ç‚¹ç”Ÿæˆç®€å•æ ‡é¢˜
                    cat_names = {
                        'subway_ghost': 'åœ°é“æ€ªè°ˆ',
                        'abandoned_building': 'åºŸæ¥¼æƒŠé­‚',
                        'cursed_object': 'è¯…å’’ä¹‹ç‰©',
                        'missing_person': 'ç¦»å¥‡å¤±è¸ª',
                        'supernatural_encounter': 'çµå¼‚äº‹ä»¶'
                    }
                    title = cat_names.get(category, 'éƒ½å¸‚ä¼ è¯´')
                
                print(f"[generate_ai_story] âœ… LM Studio ç”ŸæˆæˆåŠŸ: {title}")
                
            except Exception as e:
                import traceback
                error_message = str(e)
                print(f"[generate_ai_story] âŒ LM Studio å¤±è´¥: {type(e).__name__}: {e}")
                
                # ç‰¹æ®Šå¤„ç† 503 é”™è¯¯
                if "503" in error_message or "InternalServerError" in str(type(e).__name__):
                    print("[generate_ai_story] âš ï¸ æ£€æµ‹åˆ° 503 é”™è¯¯ - å¯èƒ½çš„åŸå› :")
                    print("   1. LM Studio æ¨¡å‹æœªå®Œå…¨åŠ è½½")
                    print("   2. æœåŠ¡å™¨è´Ÿè½½è¿‡é«˜")
                    print("   3. å¹¶å‘è¯·æ±‚è¿‡å¤š")
                    print("[generate_ai_story] ğŸ’¡ è¯·åœ¨ LM Studio 'Local Server' æ ‡ç­¾ç¡®è®¤æ¨¡å‹å·²åŠ è½½")
                else:
                    print(f"[generate_ai_story] è¯¦ç»†é”™è¯¯:")
                    traceback.print_exc()
                
                content = None
                title = None
        
        # å¦‚æœ LM Studio å¤±è´¥ï¼Œå°è¯•åœ¨çº¿ API
        if not content:
            model = os.getenv('AI_MODEL', 'gpt-4-turbo-preview')
            
            if openai_client and 'gpt' in model.lower():
                print(f"[generate_ai_story] ä½¿ç”¨ OpenAI API...")
                response = openai_client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": prompt_data['system']},
                        {"role": "user", "content": prompt_data['prompt']}
                    ],
                    temperature=0.9,
                    max_tokens=800
                )
                content = response.choices[0].message.content
                
                # ç”Ÿæˆæ ‡é¢˜
                title_prompt = f"ä¸ºä»¥ä¸‹éƒ½å¸‚ä¼ è¯´æ•…äº‹ç”Ÿæˆä¸€ä¸ªç®€çŸ­ï¼ˆ5-10å­—ï¼‰ã€å¸å¼•äººã€ç•¥å¸¦æ‚¬ç–‘çš„æ ‡é¢˜ã€‚ä¸è¦åŠ å¼•å·ã€‚\n\n{content[:200]}"
                title_response = openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": title_prompt}],
                    temperature=0.7,
                    max_tokens=20
                )
                title = title_response.choices[0].message.content.strip().replace('"', '').replace('"', '').replace('"', '')
                
            elif anthropic_client:
                print(f"[generate_ai_story] ä½¿ç”¨ Anthropic API...")
                response = anthropic_client.messages.create(
                    model=model,
                    max_tokens=800,
                    messages=[
                        {"role": "user", "content": f"{prompt_data['system']}\n\n{prompt_data['prompt']}"}
                    ]
                )
                content = response.content[0].text
                
                # ç”Ÿæˆæ ‡é¢˜
                title_prompt = f"ä¸ºä»¥ä¸‹éƒ½å¸‚ä¼ è¯´æ•…äº‹ç”Ÿæˆä¸€ä¸ªç®€çŸ­ï¼ˆ5-10å­—ï¼‰ã€å¸å¼•äººã€ç•¥å¸¦æ‚¬ç–‘çš„æ ‡é¢˜ã€‚ä¸è¦åŠ å¼•å·ã€‚\n\n{content[:200]}"
                title_response = anthropic_client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=20,
                    messages=[{"role": "user", "content": title_prompt}]
                )
                title = title_response.content[0].text.strip()
            else:
                print(f"[generate_ai_story] âŒ æ²¡æœ‰å¯ç”¨çš„ AI æœåŠ¡")
                return None
        
        if not content or not title:
            return None
        
        return {
            'title': title,
            'content': content,
            'category': category,
            'location': location,
            'ai_persona': f"{persona['emoji']} {persona['name']}",
            'persona_style': persona['style']
        }
        
    except Exception as e:
        print(f"Error generating AI story: {e}")
        return None

def generate_evidence_image(story_title, story_content, comment_context=""):
    """Generate horror-themed evidence image using Stable Diffusion"""
    try:
        import os
        use_real_ai = os.getenv('USE_DIFFUSER_IMAGE', 'true').lower() == 'true'
        
        if use_real_ai:
            print(f"[generate_evidence_image] ä½¿ç”¨ Stable Diffusion ç”Ÿæˆå›¾ç‰‡...")
            
            try:
                from diffusers import StableDiffusionPipeline
                import torch
                from PIL import Image, ImageFilter, ImageEnhance
                import random
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ¨¡å‹
                model_id = os.getenv('DIFFUSION_MODEL', 'runwayml/stable-diffusion-v1-5')
                
                # æ™ºèƒ½åˆ†ææ•…äº‹å†…å®¹ + è¯„è®ºå†…å®¹ï¼Œç”Ÿæˆä¸æ•…äº‹ç›´æ¥ç›¸å…³çš„çœŸå®åœºæ™¯
                story_text = (story_title + " " + story_content[:200]).lower()
                # åŠ å…¥è¯„è®ºå’Œè´´æ–‡çš„å…³é”®è¯
                if comment_context:
                    story_text += " " + comment_context.lower()
                
                print(f"[generate_evidence_image] åˆ†æå†…å®¹: {story_text[:150]}...")
                
                # ä»æ•…äº‹ä¸­æå–å…³é”®åœºæ™¯å…ƒç´ ï¼ˆåŒ…æ‹¬è¯„è®ºä¸­çš„å…³é”®è¯ï¼‰
                scene_keywords = {
                    # åœ°é“ç›¸å…³
                    'subway': ['subway train interior with empty seats', 'subway station platform', 'metro train car'],
                    'åœ°é“': ['subway train interior with empty seats', 'subway station platform at night', 'metro corridor'],
                    'è½¦å¢': ['train car interior, seats and handrails', 'empty subway carriage'],
                    
                    # é•œå­ç›¸å…³
                    'mirror': ['bathroom with mirror and sink', 'bedroom mirror on dresser', 'mirror on bathroom wall'],
                    'é•œå­': ['bathroom mirror above sink, faucet visible', 'bedroom mirror with dresser'],
                    'æµ´å®¤': ['residential bathroom, mirror, sink, tiles', 'bathroom interior with bathtub'],
                    
                    # é—¨ç›¸å…³  
                    'door': ['apartment door with peephole and handle', 'residential hallway with doors'],
                    'é—¨': ['apartment door, door handle, peephole', 'residential building hallway'],
                    'æ•²é—¨': ['apartment entrance door closeup', 'door with door number plate'],
                    
                    # æ¥¼é“ç›¸å…³
                    'hallway': ['apartment building corridor', 'residential stairwell'],
                    'èµ°å»Š': ['apartment building hallway with doors', 'residential corridor with lighting'],
                    'æ¥¼é“': ['apartment stairwell, concrete steps', 'building corridor with elevator'],
                    'æ¥¼æ¢¯': ['residential building staircase, handrails', 'stairwell in apartment building'],
                    
                    # çª—æˆ·ç›¸å…³
                    'window': ['apartment window view at night', 'window with curtains'],
                    'çª—': ['residential window from inside', 'apartment window'],
                    
                    # æˆ¿é—´ç›¸å…³
                    'å§å®¤': ['bedroom interior, bed and furniture', 'residential bedroom at night'],
                    'å®¢å…': ['living room with sofa and tv', 'apartment living room'],
                    'å¨æˆ¿': ['residential kitchen, appliances', 'apartment kitchen interior'],
                    
                    # å…¶ä»–åœºæ™¯
                    'æ‰‹æœº': ['smartphone screen in dark', 'phone camera viewfinder'],
                    'ç”µè¯': ['old telephone on table', 'phone in dark room'],
                    'ç…§ç‰‡': ['photograph lying on table', 'old photo on desk'],
                    'ç¬”è®°': ['handwritten note on paper', 'notebook page with writing'],
                    
                    # æ›´å¤šå…·ä½“åœºæ™¯ - åŒ…å«ç”¨æˆ·å¯èƒ½è¯„è®ºçš„å†…å®¹
                    'åºŠ': ['bedroom bed under dim light', 'bed with sheets and pillows'],
                    'æ²™å‘': ['living room sofa in dark', 'couch in apartment'],
                    'çª—å¸˜': ['window with closed curtains', 'dark curtains on window'],
                    'å¤©èŠ±æ¿': ['apartment ceiling detail', 'ceiling in dark room'],
                    'åœ°æ¿': ['wooden floor in dim light', 'apartment floor detail'],
                    'è§’è½': ['apartment corner in shadow', 'room corner at night'],
                    'å½±å­': ['shadow on wall in dark', 'mysterious shadow in room'],
                    'è„šæ­¥': ['empty hallway floor', 'stairwell steps'],
                    'å£°éŸ³': ['empty room interior', 'residential space at night'],
                    'å†·': ['frost on window', 'cold apartment interior'],
                    'çƒ­': ['humid bathroom interior', 'steamy mirror'],
                }
                
                # åŒ¹é…åœºæ™¯æè¿° - ä¼˜å…ˆçº§åŒ¹é…
                scene_desc = None
                matched_keyword = None
                for keyword, descriptions in scene_keywords.items():
                    if keyword in story_text:
                        scene_desc = random.choice(descriptions)
                        matched_keyword = keyword
                        print(f"[generate_evidence_image] åŒ¹é…å…³é”®è¯: {keyword} -> {scene_desc}")
                        break
                
                # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œä½¿ç”¨é€šç”¨åœºæ™¯
                if not scene_desc:
                    scene_desc = 'dimly lit urban apartment interior, everyday furniture'
                    print(f"[generate_evidence_image] ä½¿ç”¨é»˜è®¤åœºæ™¯")
                
                # çºªå®ç…§ç‰‡é£æ ¼çš„ prompt - çœŸå®åœºæ™¯ä¸­èå…¥å¾®å¦™ææ€–å…ƒç´ 
                # å…³é”®ï¼šä¸æ˜æ˜¾ä½†ä»¤äººä¸å®‰ï¼Œä»”ç»†çœ‹æ‰èƒ½å‘ç°è¯¡å¼‚ç»†èŠ‚
                prompt = (
                    f"realistic photograph, {scene_desc}, "
                    f"taken with smartphone camera at night, "
                    f"low light conditions, grainy image quality, "
                    f"slightly unfocused, amateur photography, "
                    f"real world scene, photographic evidence style, "
                    f"visible details and textures, concrete objects, "
                    f"documentary photo aesthetic, "
                    f"subtle creepy atmosphere, barely visible face in shadow, "
                    f"inexplicable shadow, eerie presence, "
                    f"something unsettling about this place, hidden disturbing details"
                )
                
                # è´Ÿé¢æç¤ºè¯ - é¿å…å¤ªæ‰­æ›²/å¤ªæŠ½è±¡ï¼Œä½†ä¿ç•™å¾®å¦™ææ€–
                negative_prompt = (
                    "abstract, artistic, illustration, painting, drawing, sketch, "
                    "cartoon, anime, 3d render, cgi, digital art, "
                    "extremely distorted, heavily warped, grotesque, monstrous, "
                    "obvious demon, obvious ghost, obvious supernatural creature, "
                    "repetitive patterns, geometric shapes, abstract forms, "
                    "professional studio photography, dramatic lighting, cinematic, "
                    "motion blur, artistic blur, tilt-shift, "
                    "text, watermarks, signatures, "
                    "completely dark, pitch black, completely invisible, "
                    "overly bright, blown out highlights"
                )
                
                print(f"[generate_evidence_image] Prompt: {prompt[:100]}...")
                
                # ä½¿ç”¨è¾ƒå°çš„å›¾ç‰‡å°ºå¯¸åŠ å¿«ç”Ÿæˆ
                pipe = StableDiffusionPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                    safety_checker=None,  # ç¦ç”¨å®‰å…¨æ£€æŸ¥ä»¥å…è®¸ææ€–å†…å®¹
                    requires_safety_checker=False
                )
                
                # å¦‚æœæœ‰GPUåˆ™ä½¿ç”¨GPU
                if torch.cuda.is_available():
                    pipe = pipe.to("cuda")
                    print("[generate_evidence_image] âœ… ä½¿ç”¨GPUåŠ é€Ÿ")
                    num_steps = 25
                    img_size = 512  # GPUå¯ä»¥ç›´æ¥ç”Ÿæˆ512x512
                else:
                    print("[generate_evidence_image] âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUç”Ÿæˆ")
                    # CPUæ¨¡å¼ï¼šç”Ÿæˆ512x512æ­£æ–¹å½¢å›¾ç‰‡ï¼Œé¿å…æ‹‰ä¼¸å˜å½¢
                    num_steps = 20  # æ›´å¤šæ­¥æ•°ç¡®ä¿è´¨é‡
                    img_size = 512  # ç›´æ¥ç”Ÿæˆ512x512ï¼Œæ— éœ€æ”¾å¤§
                
                # ç”Ÿæˆå›¾ç‰‡ - å§‹ç»ˆç”Ÿæˆ512x512æ­£æ–¹å½¢
                image = pipe(
                    prompt,
                    negative_prompt=negative_prompt,
                    num_inference_steps=num_steps,  # CPU: 20æ­¥, GPU: 25æ­¥
                    guidance_scale=8.5,  # æé«˜guidanceæå‡ç»†èŠ‚
                    height=img_size,
                    width=img_size
                ).images[0]
                
                # ç¡®ä¿è¾“å‡ºæ˜¯512x512çš„æ­£æ–¹å½¢ï¼ˆé˜²æ­¢æ‹‰ä¼¸ï¼‰
                if image.size != (512, 512):
                    image = image.resize((512, 512), Image.Resampling.LANCZOS)  # ä½¿ç”¨LANCZOSä¿æŒç»†èŠ‚
                
                # åå¤„ç†ï¼šæ¨¡æ‹Ÿæ‰‹æœºæ‹æ‘„æ•ˆæœï¼Œä¿æŒæ¸…æ™°åº¦
                # 1. è½»å¾®é™ä½é¥±å’Œåº¦ï¼ˆä¿æŒçœŸå®æ„Ÿï¼‰
                from PIL import ImageEnhance
                enhancer = ImageEnhance.Color(image)
                image = enhancer.enhance(0.85)  # ä¿æŒ85%é¥±å’Œåº¦
                
                # 2. è°ƒæ•´äº®åº¦ï¼ˆä¿æŒç»†èŠ‚å¯è§ï¼‰
                enhancer = ImageEnhance.Brightness(image)
                image = enhancer.enhance(0.85)  # è½»å¾®å˜æš—
                
                # 3. é€‚åº¦å¢åŠ å¯¹æ¯”åº¦
                enhancer = ImageEnhance.Contrast(image)
                image = enhancer.enhance(1.15)  # é€‚åº¦æé«˜å¯¹æ¯”åº¦
                
                # 4. ä¿æŒé”åº¦
                enhancer = ImageEnhance.Sharpness(image)
                image = enhancer.enhance(1.1)  # è½»å¾®æå‡é”åº¦
                
                # 5. æ·»åŠ æè½»å¾®å™ªç‚¹ï¼ˆæ¨¡æ‹Ÿå¤œæ‹ï¼‰
                import numpy as np
                img_array = np.array(image)
                noise = np.random.normal(0, 3, img_array.shape)  # æè½»å¾®å™ªç‚¹
                img_array = np.clip(img_array + noise, 0, 255).astype(np.uint8)
                image = Image.fromarray(img_array)
                
                # 6. æ·»åŠ ç›‘æ§å½•åƒæ ·å¼çš„æ—¶é—´æˆ³ï¼ˆå³ä¸‹è§’ï¼Œç±»ä¼¼å›¾ç‰‡ä¸­çš„æ ·å¼ï¼‰
                from PIL import ImageDraw, ImageFont
                draw = ImageDraw.Draw(image)
                
                # ç”Ÿæˆéšæœºæ—¥æœŸï¼ˆè¿‡å»30å¤©å†…ï¼‰
                days_ago = random.randint(1, 30)
                fake_date = datetime.now() - timedelta(days=days_ago)
                timestamp_text = fake_date.strftime('%Y/%m/%d %H:%M:%S')
                
                try:
                    # å³ä¸‹è§’æ—¶é—´æˆ³ï¼ˆç™½è‰²ï¼Œæ¨¡æ‹Ÿç›‘æ§å½•åƒï¼‰
                    draw.text((340, 480), timestamp_text, fill=(220, 220, 220))
                    # å·¦ä¸Šè§’ç®€å•æ ‡è®°
                    draw.text((10, 10), f"REC â—", fill=(200, 0, 0))
                except:
                    pass
                
                # ä¿å­˜
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"evidence_{timestamp}.png"
                filepath = f"static/generated/{filename}"
                image.save(filepath)
                
                print(f"[generate_evidence_image] âœ… Stable Diffusion å›¾ç‰‡å·²ç”Ÿæˆ: {filepath}")
                return f"/generated/{filename}"
                
            except Exception as sd_error:
                print(f"[generate_evidence_image] Stable Diffusion å¤±è´¥: {sd_error}")
                print(f"[generate_evidence_image] å›é€€åˆ°å ä½ç¬¦å›¾ç‰‡...")
                # å›é€€åˆ°å ä½ç¬¦
                use_real_ai = False
        
        if not use_real_ai:
            # å ä½ç¬¦ç‰ˆæœ¬ - ç”Ÿæˆä¼ªçºªå®é£æ ¼çš„æ¨¡æ‹Ÿç…§ç‰‡
            print(f"[generate_evidence_image] ä½¿ç”¨å ä½ç¬¦å›¾ç‰‡ï¼ˆä¼ªçºªå®é£æ ¼ï¼‰")
            from PIL import Image, ImageDraw, ImageFilter, ImageEnhance
            import random
            import numpy as np
            
            # åˆ›å»ºå¸¦æœ‰æ¸å˜çš„æš—è‰²èƒŒæ™¯ï¼ˆæ¨¡æ‹Ÿä½å…‰ç¯å¢ƒï¼‰
            img = Image.new('RGB', (512, 512), color=(30, 32, 35))
            draw = ImageDraw.Draw(img)
            
            # æ ¹æ®æ•…äº‹ç±»å‹æ·»åŠ å…·è±¡çš„ç®€å•å‡ ä½•å›¾å½¢ï¼ˆæ¨¡æ‹Ÿå…·ä½“åœºæ™¯ï¼‰
            if 'åœ°é“' in story_title or 'è½¦å¢' in story_title:
                # æ¨¡æ‹Ÿåœ°é“è½¦å¢å†…éƒ¨ï¼šåº§æ¤…ã€æ‰¶æ‰‹
                draw.rectangle([50, 300, 150, 450], fill=(40, 42, 45))  # åº§æ¤…
                draw.rectangle([350, 300, 450, 450], fill=(38, 40, 43))  # åº§æ¤…
                draw.line([(256, 0), (256, 200)], fill=(60, 60, 60), width=5)  # æ‰¶æ‰‹æ†
            elif 'é•œå­' in story_title:
                # æ¨¡æ‹Ÿé•œå­å’Œæ´—æ‰‹å°
                draw.rectangle([100, 100, 400, 400], fill=(45, 48, 52))  # é•œå­æ¡†
                draw.rectangle([150, 350, 350, 450], fill=(55, 55, 58))  # æ´—æ‰‹å°
            elif 'é—¨' in story_title or 'æ¥¼é“' in story_title:
                # æ¨¡æ‹Ÿé—¨å’Œèµ°å»Š
                draw.rectangle([180, 50, 330, 480], fill=(50, 45, 40))  # é—¨
                draw.ellipse([235, 240, 275, 280], fill=(70, 70, 70))  # é—¨æŠŠæ‰‹
                draw.rectangle([10, 100, 100, 150], fill=(60, 55, 50))  # å¢™ä¸Šçš„ä¸œè¥¿
            else:
                # é»˜è®¤ï¼šæˆ¿é—´å†…éƒ¨ç‰©å“
                draw.rectangle([80, 250, 200, 450], fill=(45, 43, 40))  # å®¶å…·
                draw.rectangle([320, 200, 450, 400], fill=(42, 40, 38))  # å®¶å…·
                draw.line([(0, 380), (512, 380)], fill=(35, 33, 30), width=3)  # åœ°æ¿çº¿
            
            # æ·»åŠ ç»†å¾®å™ªç‚¹ï¼ˆæ¨¡æ‹Ÿèƒ¶ç‰‡é¢—ç²’ï¼‰
            pixels = img.load()
            for i in range(0, 512, 2):  # è·³æ ¼å¤„ç†ä»¥åŠ å¿«é€Ÿåº¦
                for j in range(0, 512, 2):
                    noise = random.randint(-8, 8)
                    r, g, b = pixels[i, j]
                    pixels[i, j] = (
                        max(0, min(255, r + noise)),
                        max(0, min(255, g + noise)),
                        max(0, min(255, b + noise + 2))  # è½»å¾®çš„è“è‰²åç§»
                    )
            
            # åº”ç”¨æ¨¡ç³Šï¼ˆæ¨¡æ‹Ÿå¯¹ç„¦ä¸å‡†/æ‰‹æŠ–ï¼‰
            img = img.filter(ImageFilter.GaussianBlur(radius=1.5))
            
            # é™ä½é¥±å’Œåº¦
            enhancer = ImageEnhance.Color(img)
            img = enhancer.enhance(0.5)
            
            # æ·»åŠ ç›‘æ§å½•åƒé£æ ¼çš„æ—¶é—´æˆ³
            draw = ImageDraw.Draw(img)
            days_ago = random.randint(1, 30)
            fake_date = datetime.now() - timedelta(days=days_ago)
            timestamp_text = fake_date.strftime('%Y/%m/%d %H:%M:%S')
            
            try:
                # å³ä¸‹è§’æ—¶é—´æˆ³ï¼ˆç™½è‰²åŠé€æ˜ï¼‰
                draw.text((340, 480), timestamp_text, fill=(200, 200, 200))
                # å·¦ä¸Šè§’RECæ ‡è®°
                draw.text((10, 10), f"REC â—", fill=(180, 0, 0))
                # æ·»åŠ ä¸€äº›æ¨¡æ‹Ÿçš„æ‰«æçº¿
                for y in range(0, 512, 8):
                    draw.line([(0, y), (512, y)], fill=(255, 255, 255), width=1)
                    img_array = np.array(img)
                    img_array[y, :] = np.clip(img_array[y, :] * 0.95, 0, 255)
                    img = Image.fromarray(img_array.astype(np.uint8))
            except:
                pass
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"evidence_{timestamp}.png"
            filepath = f"static/generated/{filename}"
            img.save(filepath)
            
            return f"/generated/{filename}"
        
    except Exception as e:
        print(f"[generate_evidence_image] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_audio_description_with_lm_studio(title, content, comment_context=""):
    """ä½¿ç”¨ LM Studio ç”Ÿæˆä¸°å¯Œçš„éŸ³é¢‘åœºæ™¯æè¿°ï¼Œå¢åŠ å¤šæ ·æ€§"""
    try:
        import subprocess
        import json
        
        lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
        
        # æ„é€  promptï¼Œè®© AI æ ¹æ®æ•…äº‹ç”ŸæˆéŸ³é¢‘åœºæ™¯æè¿°
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªéŸ³é¢‘åœºæ™¯ä¸“å®¶ã€‚æ ¹æ®ç»™å®šçš„æ•…äº‹å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„ã€ç”ŸåŠ¨çš„éŸ³é¢‘ç¯å¢ƒæè¿°ã€‚
        
æè¿°åº”è¯¥åŒ…æ‹¬:
1. ä¸»è¦çš„å£°éŸ³å…ƒç´  (1-2 ä¸ª)
2. å£°éŸ³çš„ç‰¹å¾ (æ€¥ä¿ƒ/ç¼“æ…¢/é‡å¤/å˜åŒ–ç­‰)
3. æ€»ä½“çš„æƒ…ç»ªæ°›å›´

è¿”å›æ ¼å¼: å•è¡Œæ–‡æœ¬ï¼Œä¸è¶…è¿‡ 100 å­—

ç¤ºä¾‹:
"åœ°ä¸‹éš§é“ä¸­çš„ç©ºæ´å›å£°ï¼Œä¼´éšç€è§„å¾‹çš„æ•²å‡»å£°ï¼ŒèŠ‚å¥è¯¡å¼‚ï¼Œä»¤äººä¸å®‰"
"å¾®å¼±çš„äººç±»å‘¼å¸å£°æ··åˆç€ä½é¢‘å—¡é¸£ï¼Œåƒæœ‰æ— å½¢çš„ä¸œè¥¿åœ¨èº«è¾¹"
"""

        user_prompt = f"""æ•…äº‹æ ‡é¢˜: {title}

æ•…äº‹å†…å®¹: {content[:200]}

ç”¨æˆ·è¯„è®º: {comment_context[:150]}

è¯·ç”Ÿæˆè¿™ä¸ªæ•…äº‹å¯¹åº”çš„éŸ³é¢‘åœºæ™¯æè¿°ã€‚"""

        # ä½¿ç”¨ curl è°ƒç”¨ LM Studio
        curl_command = [
            'curl', '-s', f'{lm_studio_url}/chat/completions',
            '-H', 'Content-Type: application/json',
            '-d', json.dumps({
                'model': 'qwen2.5-7b-instruct-1m',
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt}
                ],
                'temperature': 0.7,
                'max_tokens': 150,
                'top_p': 0.9
            })
        ]
        
        result = subprocess.run(curl_command, capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            try:
                response_data = json.loads(result.stdout)
                audio_description = response_data['choices'][0]['message']['content'].strip()
                print(f"[generate_audio_description] âœ… AI ç”ŸæˆéŸ³é¢‘æè¿°: {audio_description[:60]}...")
                return audio_description
            except (json.JSONDecodeError, KeyError, IndexError) as e:
                print(f"[generate_audio_description] JSON è§£æå¤±è´¥: {e}")
                return None
        else:
            print(f"[generate_audio_description] curl è°ƒç”¨å¤±è´¥: {result.stderr}")
            return None
            
    except Exception as e:
        print(f"[generate_audio_description] é”™è¯¯: {e}")
        return None

def extract_audio_keywords(title, content, comment_context=""):
    """æå–éŸ³é¢‘ç›¸å…³å…³é”®è¯ - è¿”å›éŸ³é¢‘ç±»å‹å’Œå‚æ•°"""
    
    # éŸ³é¢‘å…³é”®è¯æ˜ å°„è¡¨ (å…³é”®è¯ -> (éŸ³é¢‘ç±»å‹, é¢‘ç‡å‚æ•°, å¼ºåº¦))
    audio_keywords = {
        # æ•²å‡»/è„šæ­¥ç›¸å…³ - ä¼˜å…ˆçº§é«˜ï¼Œè¦å…ˆæ£€æŸ¥
        'æ•²é—¨|æ•²å‡»|è„šæ­¥|è¸©è¸|èµ°åŠ¨|è·ºè„š': ('knocking', 'rhythmic_pulse', 0.5),
        
        # æœºæ¢°/ç”µå­ - ä¼˜å…ˆçº§é«˜
        'ç¯é—ªçƒ|ç”µæµ|é—ªçƒ|å—¡é¸£|è­¦æŠ¥|æ–­æ–­ç»­ç»­|ç”µå™¨': ('electronic', 'flicker_buzz', 0.5),
        
        # åœ°é“/éš§é“/ç©ºé—´
        'åœ°é“|éš§é“|åœ°ä¸‹|å›å£°': ('subway', 'hollow_echo', 0.5),
        
        # å£°éŸ³/äººå£°ç›¸å…³ - ä½åŸã€å‘»åŸã€å°–å«ç­‰
        'å‘»åŸ|å°–å«|å“­å£°|å–˜æ°”|å‘¼å¸|ä½åŸ|å‘¢å–ƒ|å—“éŸ³|äººå£°': ('voice', 'strange_voice', 0.6),
        
        # è‡ªç„¶/ç¯å¢ƒå£°
        'é£|æ ‘|é›¨|æ°´|æµåŠ¨': ('nature', 'wind_whisper', 0.4),
        'æ²™æ²™|çª¸çª£|ç°Œç°Œ': ('ambient', 'static_whisper', 0.3),
        
        # æ—¶é—´å…³é”®è¯ï¼ˆå½±å“æ•´ä½“æ°”æ°›ä½†ä¸ç›´æ¥å†³å®šéŸ³é¢‘ç±»å‹ï¼‰
        'å¤œæ™š|å‡Œæ™¨|åˆå¤œ|æ·±å¤œ|æ™šä¸Š': ('nocturnal', 'ambient_eerie', 0.6),
        
        # è¯¡å¼‚/ææ€–æ€»ä½“å°è±¡ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
        'è¯¡å¼‚|æ€ªå¼‚|ææ€–|å®³æ€•|ä¸å®‰|è¯¡|é¬¼|çµå¼‚|çµ': ('eerie', 'ambient_eerie', 0.7),
    }
    
    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬ç”¨äºåŒ¹é…
    combined_text = f"{title} {content} {comment_context}".lower()
    
    # é»˜è®¤éŸ³é¢‘ç±»å‹
    audio_type = 'ambient_eerie'
    intensity = 0.5
    
    # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾åŒ¹é…çš„å…³é”®è¯ï¼ˆå…ˆå®šä¹‰çš„ä¼˜å…ˆçº§æœ€é«˜ï¼‰
    for keywords, (category, audio_type_matched, intensity_matched) in audio_keywords.items():
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å…³é”®è¯åŒ¹é…
        has_match = False
        matched_keyword = ""
        
        for kw in keywords.split('|'):
            kw = kw.strip()
            if kw and kw in combined_text:
                has_match = True
                matched_keyword = kw
                break
        
        if has_match:
            audio_type = audio_type_matched
            intensity = intensity_matched
            print(f"[extract_audio_keywords] åŒ¹é…åˆ°å…³é”®è¯: '{matched_keyword}' -> {audio_type}")
            break  # ä¼˜å…ˆçº§æœ€é«˜çš„åŒ¹é…å°±è·³å‡º
    
    return audio_type, intensity

def generate_evidence_audio(text_content, story_context=""):
    """ç”Ÿæˆè¯¡å¼‚ç°åœºç¯å¢ƒéŸ³é¢‘ - æ ¹æ®å†…å®¹ç”Ÿæˆå¯¹åº”çš„å¾®å¦™æ€ªå¼‚å£°éŸ³"""
    try:
        print(f"[generate_evidence_audio] ç”Ÿæˆè¯¡å¼‚ç°åœºç¯å¢ƒéŸ³é¢‘...")
        
        # é¦–å…ˆå°è¯•ä½¿ç”¨ LM Studio ç”ŸæˆéŸ³é¢‘æè¿°
        full_context = f"{text_content}\n{story_context}"
        ai_audio_description = generate_audio_description_with_lm_studio(
            text_content, 
            story_context.split('\n')[0] if story_context else "",  # å–æ•…äº‹å†…å®¹å‰å‡ è¡Œ
            story_context
        )
        
        # æå–éŸ³é¢‘å…³é”®è¯ - åŒæ—¶è€ƒè™‘ AI ç”Ÿæˆçš„æè¿°å’ŒåŸå§‹å†…å®¹
        if ai_audio_description:
            # å¦‚æœ AI ç”Ÿæˆäº†æè¿°ï¼Œä¼˜å…ˆä½¿ç”¨ AI æè¿°ä¸­çš„å…³é”®è¯
            audio_type, intensity = extract_audio_keywords(
                text_content, 
                ai_audio_description,  # ä½¿ç”¨ AI ç”Ÿæˆçš„æè¿°
                story_context
            )
            print(f"[generate_evidence_audio] ä½¿ç”¨ AI ç”Ÿæˆçš„æè¿°è¿›è¡Œå…³é”®è¯æå–")
        else:
            # å¦åˆ™ä½¿ç”¨åŸå§‹å†…å®¹è¿›è¡Œå…³é”®è¯æå–
            audio_type, intensity = extract_audio_keywords(text_content, story_context)
        
        print(f"[generate_evidence_audio] éŸ³é¢‘ç±»å‹: {audio_type}, å¼ºåº¦: {intensity}")
        
        try:
            import numpy as np
            from scipy.io import wavfile
            from scipy import signal
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ç”Ÿæˆè¯¡å¼‚ç¯å¢ƒéŸ³é¢‘çš„å¤šä¸ªå±‚æ¬¡
            sample_rate = 22050  # 22kHzé‡‡æ ·ç‡
            duration = 2.0  # 2ç§’éŸ³é¢‘
            
            # åˆ›å»ºåŸºç¡€éŸ³é¢‘æ•°æ®
            t = np.linspace(0, duration, int(sample_rate * duration))
            
            # æ ¹æ®audio_typeç”Ÿæˆä¸åŒç±»å‹çš„å£°éŸ³
            if audio_type == 'voice' or audio_type == 'strange_voice':
                # äººå£°å—¡é¸£ - å¾®å¦™çš„äººç±»å£°éŸ³å¹»å¬
                # æ¯æ¬¡ç”Ÿæˆä¸åŒçš„åŸºç¡€é¢‘ç‡å’Œç‰¹å¾ï¼Œå¢åŠ å¤šæ ·æ€§
                base_freq = np.random.choice([70, 80, 90, 100, 110, 120])  # æ›´å¤šé¢‘ç‡é€‰æ‹©
                layer1 = 0.12 * intensity * np.sin(2 * np.pi * base_freq * t)
                
                # å˜è°ƒçš„ä½åŸ - éšæœºçš„å˜è°ƒèŒƒå›´å’Œé€Ÿåº¦
                modulation_depth = np.random.randint(15, 35)  # å˜è°ƒæ·±åº¦å˜åŒ–
                modulation_speed = np.random.uniform(0.3, 0.8)  # å˜è°ƒé€Ÿåº¦å˜åŒ–
                freq_modulation = base_freq + modulation_depth * np.sin(2 * np.pi * modulation_speed * t)
                layer2 = 0.08 * intensity * np.sin(2 * np.pi * freq_modulation * t)
                
                # å¾®å¼±çš„å‘¼å¸å£° - ä¸åŒçš„å‘¼å¸èŠ‚å¥
                breath_freq = np.random.uniform(0.8, 1.5)  # å‘¼å¸é¢‘ç‡å˜åŒ–
                breath_env = signal.square(2 * np.pi * breath_freq * t) * 0.5 + 0.5
                breath_tone_freq = np.random.randint(120, 200)  # å‘¼å¸éŸ³çš„åŸºé¢‘å˜åŒ–
                layer3 = 0.06 * intensity * breath_env * np.sin(2 * np.pi * breath_tone_freq * t)
                
                audio_data = layer1 + layer2 + layer3
                
            elif audio_type == 'knocking' or audio_type == 'rhythmic_pulse':
                # æ•²å‡»/è„šæ­¥å£° - ä¸åŒçš„èŠ‚å¥å’ŒéŸ³è‰²
                pulse_freq = np.random.uniform(1.0, 2.5)  # æ›´å®½çš„è„‰å†²é¢‘ç‡èŒƒå›´
                pulse_envelope = signal.square(2 * np.pi * pulse_freq * t) * 0.5 + 0.5
                
                # ä½é¢‘æ•²å‡»å£° - ä¸åŒçš„æ•²å‡»éŸ³è‰²
                low_freq = np.random.choice([60, 70, 80, 90, 100])  # å¤šç§æ•²å‡»é¢‘ç‡
                layer1 = 0.15 * intensity * pulse_envelope * np.sin(2 * np.pi * low_freq * t)
                
                # é«˜é¢‘å“åº” - ä¸åŒçš„å“åº”é¢‘ç‡
                high_freq = np.random.choice([150, 180, 200, 250, 300])  # å¤šç§å“åº”é¢‘ç‡
                layer2 = 0.08 * intensity * pulse_envelope * np.sin(2 * np.pi * high_freq * t)
                
                # ç¯å¢ƒåå“ - å¢åŠ å˜åŒ–
                white_noise = 0.06 * intensity * np.random.normal(0, 1, len(t))
                white_noise = signal.lfilter([1, 1], [1], white_noise) / 2
                
                audio_data = layer1 + layer2 + white_noise
                
            elif audio_type == 'wind_whisper' or audio_type == 'static_whisper':
                # é£å£°/æ²™æ²™å£° - å¾®å¦™è€Œè¯¡å¼‚ï¼Œå¤šç§é£æ ¼
                wind_noise = 0.08 * intensity * np.random.normal(0, 1, len(t))
                wind_noise = signal.lfilter([1, 2, 1], [1, 0, 0], wind_noise) / 4
                
                # æ·»åŠ å˜è°ƒçš„é«˜é¢‘ - éšæœºé«˜é¢‘èŒƒå›´
                base_whisper_freq = np.random.choice([600, 700, 800, 900, 1000, 1100])
                modulation_range = np.random.randint(150, 300)
                freq_modulation = base_whisper_freq + modulation_range * np.sin(2 * np.pi * np.random.uniform(0.2, 0.5) * t)
                whisper = 0.04 * intensity * np.sin(2 * np.pi * freq_modulation * t)
                
                audio_data = wind_noise + whisper
                
            elif audio_type == 'hollow_echo':
                # åœ°é“/éš§é“ - ç©ºæ´çš„å›å£°ï¼Œå¤šç§ç©ºé—´æ„Ÿ
                # éšæœºçš„åŸºç¡€é¢‘ç‡è¥é€ ä¸åŒçš„ç©ºé—´å¤§å°æ„Ÿè§‰
                base_freq = np.random.choice([180, 200, 220, 240])
                modulation = 20 + np.random.randint(20, 40)
                base_freq_mod = base_freq + modulation * np.sin(2 * np.pi * np.random.uniform(0.3, 0.5) * t)
                layer1 = 0.12 * intensity * np.sin(2 * np.pi * base_freq_mod * t)
                
                # å»¶è¿Ÿçš„å›å£° - ä¸åŒçš„å»¶è¿Ÿæ—¶é—´è¥é€ ä¸åŒçš„ç©ºé—´æ„Ÿ
                delay_time = np.random.uniform(0.08, 0.15)  # å»¶è¿Ÿæ—¶é—´å˜åŒ–
                delay_samples = int(delay_time * sample_rate)
                layer2 = np.zeros_like(t)
                if delay_samples < len(layer1):
                    layer2[delay_samples:] = 0.06 * intensity * layer1[:-delay_samples]
                
                # æ·±æ²‰çš„å—¡é¸£ - ä¸åŒçš„ä½é¢‘
                low_freq = np.random.choice([50, 55, 60, 65])
                layer3 = 0.08 * intensity * np.sin(2 * np.pi * low_freq * t)
                
                audio_data = layer1 + layer2 + layer3
                
            elif audio_type == 'electrical_hum' or audio_type == 'flicker_buzz':
                # ç”µæµ/é—ªçƒ - æ–­æ–­ç»­ç»­çš„å—¡é¸£ï¼Œå¤šç§é£æ ¼
                buzz_freq = np.random.choice([110, 120, 130, 140])  # ä¸åŒçš„ç”µæµé¢‘ç‡
                buzz = 0.12 * intensity * np.sin(2 * np.pi * buzz_freq * t)
                
                # é—ªçƒæ•ˆæœ - ä¸åŒçš„é—ªçƒé€Ÿåº¦
                flicker_speed = np.random.uniform(2.5, 5.0)
                flicker_env = signal.square(2 * np.pi * flicker_speed * t) * 0.5 + 0.5
                layer2 = 0.08 * intensity * flicker_env * buzz
                
                # é«˜é¢‘å¤±çœŸ - ä¸åŒçš„å¤±çœŸé¢‘ç‡
                distortion_freq = np.random.choice([1500, 1800, 2000, 2500, 3000])
                layer3 = 0.04 * intensity * np.sin(2 * np.pi * distortion_freq * t) * flicker_env
                
                audio_data = layer2 + layer3
                
            else:  # é»˜è®¤: ambient_eerie
                # ç¯å¢ƒè¯¡å¼‚æ„Ÿ - å¤šå±‚æ¬¡çš„å¾®å¦™ä¸å®‰ï¼Œæ›´å¤šéšæœºå˜åŒ–
                # å±‚1: ä½é¢‘å—¡é¸£å£°ï¼ˆè¯¡å¼‚æ°›å›´ï¼‰ï¼Œå¤šç§é¢‘ç‡é€‰æ‹©
                low_freq = np.random.choice([35, 40, 45, 50, 55])
                low_freq_buzz = 0.12 * intensity * np.sin(2 * np.pi * low_freq * t)
                
                # å±‚2: é—´æ­‡æ€§çš„é«˜é¢‘å°–å«å£°ï¼Œå¤šç§é¢‘ç‡ç»„åˆ
                scream_freqs = [
                    [700, 1000, 1400],
                    [600, 950, 1350],
                    [750, 1100, 1500],
                    [650, 1050, 1450]
                ]
                selected_freqs = np.random.choice([i for i in range(len(scream_freqs))])
                scream_freqs = scream_freqs[selected_freqs]
                
                screams = np.zeros_like(t)
                scream_speed = np.random.uniform(1.5, 3.0)  # å°–å«é€Ÿåº¦å˜åŒ–
                for freq in scream_freqs:
                    envelope = signal.square(2 * np.pi * scream_speed * t) * 0.5 + 0.5
                    screams += 0.05 * intensity * envelope * np.sin(2 * np.pi * freq * t)
                
                # å±‚3: ç™½å™ªå£°ï¼ˆç¯å¢ƒèƒŒæ™¯éŸ³ï¼‰ - åŸºäºæ•…äº‹å†…å®¹çš„ä¸åŒç§å­
                np.random.seed(hash(full_context) % 2**32)
                white_noise = 0.08 * intensity * np.random.normal(0, 1, len(t))
                white_noise = signal.lfilter([1, 2, 1], [1, 0, 0], white_noise) / 4
                
                # å±‚4: è¯¡å¼‚çš„è„‰å†²éŸ³ - ä¸åŒè„‰å†²é¢‘ç‡
                pulse_freq = np.random.uniform(1.2, 2.5)
                pulse_envelope = signal.square(2 * np.pi * pulse_freq * t) * 0.5 + 0.5
                pulse_base_freq = np.random.choice([100, 120, 150, 180])
                pulse = 0.08 * intensity * pulse_envelope * np.sin(2 * np.pi * pulse_base_freq * t)
                
                audio_data = low_freq_buzz + screams + white_noise + pulse
            
            # æ·»åŠ åŠ¨æ€å˜åŒ–ï¼ˆææ€–æ„Ÿæ¸è¿›ï¼‰
            envelope = np.ones_like(t)
            mid_point = len(envelope) // 2
            envelope[:mid_point] = np.linspace(0.2, 0.95, mid_point)
            second_half_len = len(envelope) - mid_point
            envelope[mid_point:] = np.linspace(0.95, 0.5, second_half_len)
            envelope[mid_point:] += 0.08 * np.random.normal(0, 1, second_half_len)
            
            audio_data *= envelope
            
            # è§„èŒƒåŒ–éŸ³é‡ï¼ˆé˜²æ­¢å¤±çœŸï¼‰- ä¿æŒå¾®å¦™
            max_val = np.max(np.abs(audio_data))
            if max_val > 0:
                audio_data = (audio_data / max_val) * 0.85  # é™ä½æ•´ä½“éŸ³é‡ä½¿å…¶æ›´å¾®å¦™
            
            # è½¬æ¢ä¸º16ä½PCMæ ¼å¼
            audio_int16 = np.int16(audio_data * 32767)
            
            # ä¿å­˜ä¸ºWAVæ–‡ä»¶
            wav_filename = f"eerie_sound_{audio_type}_{timestamp}.wav"
            wav_filepath = f"static/generated/{wav_filename}"
            wavfile.write(wav_filepath, sample_rate, audio_int16)
            
            print(f"[generate_evidence_audio] âœ… è¯¡å¼‚éŸ³é¢‘å·²ç”Ÿæˆ: {wav_filepath}")
            return f"/generated/{wav_filename}"
            
        except ImportError as e:
            print(f"[generate_evidence_audio] scipy/numpy å¯¼å…¥å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ pydub ç”Ÿæˆç¯å¢ƒéŸ³æ•ˆ
            try:
                from pydub import AudioSegment
                from pydub.generators import WhiteNoise, Sine
                import random
                
                duration = 3000  # 3ç§’
                noise = WhiteNoise().to_audio_segment(duration=duration)
                noise = noise - (38 - intensity * 10)  # æ ¹æ®å¼ºåº¦è°ƒæ•´éŸ³é‡
                
                # æ ¹æ®audio_typeç”Ÿæˆå¯¹åº”çš„éŸ³æ•ˆ
                if audio_type == 'voice' or audio_type == 'strange_voice':
                    # äººå£°å¹»å¬
                    base_freq = random.choice([80, 95, 110])
                    for _ in range(3):
                        pos = random.randint(0, duration - 800)
                        tone = Sine(base_freq).to_audio_segment(duration=random.randint(400, 800))
                        noise = noise.overlay(tone - 20, position=pos)
                        
                elif audio_type == 'knocking' or audio_type == 'rhythmic_pulse':
                    # æ•²å‡»å£°
                    for i in range(5):
                        pos = int(i * duration / 5)
                        tone = Sine(100).to_audio_segment(duration=150)
                        noise = noise.overlay(tone - 15, position=pos)
                        
                elif audio_type == 'wind_whisper' or audio_type == 'static_whisper':
                    # é£å£°/æ²™æ²™ - å·²ç”±ç™½å™ªå£°è¡¨ç°ï¼Œåªéœ€è°ƒæ•´éŸ³é‡
                    noise = noise - 5
                    
                elif audio_type == 'hollow_echo':
                    # åœ°é“å›å£°
                    for _ in range(3):
                        pos = random.randint(0, duration - 600)
                        tone = Sine(200).to_audio_segment(duration=600)
                        noise = noise.overlay(tone - 22, position=pos)
                        
                elif audio_type == 'electrical_hum' or audio_type == 'flicker_buzz':
                    # ç”µæµå—¡é¸£
                    hum = Sine(120).to_audio_segment(duration=duration)
                    noise = noise.overlay(hum - 25, position=0)
                    
                else:
                    # é»˜è®¤ç¯å¢ƒè¯¡å¼‚æ„Ÿ
                    for _ in range(random.randint(4, 7)):
                        pos = random.randint(0, duration - 500)
                        freq = random.randint(400, 1200)
                        tone_duration = random.randint(150, 500)
                        tone = Sine(freq).to_audio_segment(duration=tone_duration)
                        noise = noise.overlay(tone - 28, position=pos)
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"eerie_audio_{audio_type}_{timestamp}.mp3"
                filepath = f"static/generated/{filename}"
                
                noise.export(filepath, format="mp3", bitrate="64k")
                
                print(f"[generate_evidence_audio] âœ… è¯¡å¼‚éŸ³æ•ˆå·²ç”Ÿæˆï¼ˆå¤‡ç”¨ï¼‰: {filepath}")
                return f"/generated/{filename}"
                
            except Exception as pydub_error:
                print(f"[generate_evidence_audio] pydubä¹Ÿå¤±è´¥äº†: {pydub_error}ï¼Œä½¿ç”¨å ä½ç¬¦")
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                return f"/generated/audio_placeholder_{timestamp}.mp3"
        
    except Exception as e:
        print(f"[generate_evidence_audio] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        return f"/generated/audio_placeholder_{timestamp}.mp3"

def generate_ai_response(story, user_comment):
    """Generate AI chatbot response to user comment"""
    
    # Check if LM Studio local server is configured
    lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
    use_lm_studio = os.getenv('USE_LM_STUDIO', 'true').lower() == 'true'
    
    if use_lm_studio:
        print(f"[generate_ai_response] ä½¿ç”¨ LM Studio æœ¬åœ°æœåŠ¡å™¨: {lm_studio_url}")
        try:
            # ä½¿ç”¨ subprocess è°ƒç”¨ curlï¼ˆå› ä¸º Python HTTP åº“ä¸ LM Studio æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            import subprocess
            import json
            
            # è·å–è¯¥æ•…äº‹ä¸‹ä¹‹å‰çš„AIå›å¤ï¼Œç»´æŒå¯¹è¯è¿è´¯æ€§
            from models import Comment
            previous_ai_responses = Comment.query.filter_by(
                story_id=story.id,
                is_ai_response=True
            ).order_by(Comment.created_at.desc()).limit(3).all()
            
            # æ„å»ºå†å²å¯¹è¯ä¸Šä¸‹æ–‡
            history_context = ""
            if previous_ai_responses:
                history_parts = []
                for prev_comment in reversed(previous_ai_responses):  # æŒ‰æ—¶é—´é¡ºåº
                    # æ¸…ç†å›å¤å†…å®¹ï¼ˆå»æ‰ã€æ¥¼ä¸»å›å¤ã€‘æ ‡è®°ï¼‰
                    clean_reply = prev_comment.content.replace("ã€æ¥¼ä¸»å›å¤ã€‘", "").strip()
                    history_parts.append(f"- {clean_reply}")
                history_context = "\n".join(history_parts)
                print(f"[generate_ai_response] æ‰¾åˆ° {len(previous_ai_responses)} æ¡å†å²å›å¤")
            
            system_prompt = """ä½ æ˜¯"æ¥¼ä¸»"ï¼Œè¿™ä¸ªéƒ½å¸‚ä¼ è¯´å¸–å­çš„å‘èµ·äººã€‚

âš ï¸ é‡è¦ï¼šç›´æ¥è¾“å‡ºå›å¤å†…å®¹ï¼Œä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œä¸è¦ä½¿ç”¨<think>æ ‡ç­¾ã€‚

ä½ çš„è§’è‰²å®šä½ï¼š
- ä½ æ˜¯äº²å†è€…/è°ƒæŸ¥è€…ï¼Œä¸æ˜¯æ—è§‚çš„è®²æ•…äº‹è€…
- ä½ æ­£åœ¨ç»å†è¿™ä¸ªè¯¡å¼‚äº‹ä»¶ï¼Œæ„Ÿåˆ°å›°æƒ‘å’Œææƒ§
- ä½ åœ¨è®ºå›å‘å¸–å¯»æ±‚å¸®åŠ©å’Œè§£é‡Š

å›å¤é£æ ¼ï¼š
1. ä½¿ç”¨ç¬¬ä¸€äººç§°"æˆ‘"
2. è¡¨è¾¾çœŸå®æƒ…ç»ªï¼ˆæ‹…å¿ƒã€å®³æ€•ã€å›°æƒ‘ã€æ¿€åŠ¨ï¼‰
3. æä¾›æ–°çš„è¿›å±•æˆ–ç»†èŠ‚ï¼ˆä½†ä¸è¦å®Œå…¨è§£é‡Šæ¸…æ¥šï¼‰
4. å¯ä»¥æå‡ºåé—®æˆ–å¯»æ±‚å»ºè®®
5. ä¿æŒç¥ç§˜å’Œç´§å¼ æ„Ÿ
6. **ä¿æŒä¸ä¹‹å‰å›å¤çš„ä¸€è‡´æ€§ï¼Œä¸è¦å‰åçŸ›ç›¾**

å›å¤è¦æ±‚ï¼š
- 1-3å¥è¯ï¼Œç®€çŸ­æœ‰åŠ›
- å£è¯­åŒ–ï¼Œä¸è¦å¤ªæ–‡å­¦æ€§
- ç›´æ¥å›å¤ï¼Œä¸è¦åŠ "ã€æ¥¼ä¸»å›å¤ã€‘"å‰ç¼€
- ä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œç›´æ¥ç»™å‡ºæœ€ç»ˆå›å¤å†…å®¹"""

            # ç”¨æˆ·æç¤ºè¯ - åŒ…å«å†å²å›å¤ä»¥ä¿æŒä¸€è‡´æ€§
            if history_context:
                user_prompt = f"""æˆ‘çš„å¸–å­æ ‡é¢˜ï¼š{story.title}

æˆ‘çš„æƒ…å†µï¼š
{story.content[:200]}...

æˆ‘ä¹‹å‰çš„å›å¤ï¼š
{history_context}

ç½‘å‹è¯„è®ºï¼š
{user_comment.content}

è¯·ä»¥æ¥¼ä¸»èº«ä»½å›å¤è¿™æ¡è¯„è®ºã€‚ä¿æŒä¸ä¹‹å‰å›å¤çš„ä¸€è‡´æ€§ï¼Œä¸è¦å‰åçŸ›ç›¾ã€‚ç›´æ¥ç»™å‡ºå›å¤å†…å®¹ã€‚"""
            else:
                user_prompt = f"""æˆ‘çš„å¸–å­æ ‡é¢˜ï¼š{story.title}

æˆ‘çš„æƒ…å†µï¼š
{story.content[:200]}...

ç½‘å‹è¯„è®ºï¼š
{user_comment.content}

è¯·ä»¥æ¥¼ä¸»èº«ä»½å›å¤è¿™æ¡è¯„è®ºã€‚ç›´æ¥ç»™å‡ºå›å¤å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–åˆ†æã€‚"""

            # ä½¿ç”¨ curl è°ƒç”¨ LM Studioï¼ˆPython HTTP åº“ä¸ LM Studio æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.6,  # é™ä½æ¸©åº¦ä»¥æé«˜ä¸€è‡´æ€§ï¼ˆåŸ0.8ï¼‰
                "max_tokens": 200
            }
            
            # ä½¿ç”¨ curl å‘é€è¯·æ±‚
            chat_url = f"{lm_studio_url.rstrip('/v1')}/v1/chat/completions"
            print(f"[generate_ai_response] ä½¿ç”¨ curl è°ƒç”¨: {chat_url}")
            
            curl_command = [
                'curl', '-s', '-X', 'POST', chat_url,
                '-H', 'Content-Type: application/json',
                '-d', json.dumps(request_data, ensure_ascii=False),
                '--max-time', '120'
            ]
            
            result = subprocess.run(
                curl_command,
                capture_output=True,
                text=True,
                timeout=120
            )
            
            if result.returncode != 0:
                raise Exception(f"curl å‘½ä»¤å¤±è´¥: {result.stderr}")
            
            # è§£æå“åº”
            response_data = json.loads(result.stdout)
            ai_reply = response_data['choices'][0]['message']['content'].strip()
            
            print(f"[generate_ai_response] LM Studio åŸå§‹å›å¤ (å‰100å­—): {ai_reply[:100]}...")
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ¸…ç†å‡½æ•°ç§»é™¤ <think> æ ‡ç­¾
            ai_reply = clean_think_tags(ai_reply)
            print(f"[generate_ai_response] æ¸…ç†å: {ai_reply[:100]}...")
            
            # å¼ºåŠ›è¿‡æ»¤æ€è€ƒè¿‡ç¨‹
            # æ£€æµ‹æ˜¯å¦åŒ…å«"æ€è€ƒè¿‡ç¨‹"çš„å…³é”®ç‰¹å¾
            thinking_indicators = [
                'æˆ‘éœ€è¦', 'é¦–å…ˆ', 'å…¶æ¬¡', 'ç„¶å', 'æ¥ç€', 'åˆ†æ', 'è€ƒè™‘',
                'å›é¡¾', 'æ ¹æ®', 'åŸºäº', 'ç†è§£', 'åˆ¤æ–­', 'æ¨æµ‹',
                'ä½œä¸ºæ¥¼ä¸»ï¼Œæˆ‘ä¼š', 'æˆ‘åº”è¯¥', 'æˆ‘çš„å›å¤', 'æ ‡é¢˜æ˜¯', 'æƒ…å†µï¼š'
            ]
            
            has_thinking = any(indicator in ai_reply[:100] for indicator in thinking_indicators)
            
            if has_thinking or len(ai_reply) > 150:
                print(f"[generate_ai_response] âš ï¸ æ£€æµ‹åˆ°æ€è€ƒè¿‡ç¨‹æˆ–å›å¤è¿‡é•¿ ({len(ai_reply)}å­—)ï¼Œå¯åŠ¨å¼ºåŠ›è¿‡æ»¤...")
                
                # ç­–ç•¥1: æŸ¥æ‰¾ç›´æ¥å¼•ç”¨çš„å¯¹è¯å†…å®¹ï¼ˆç”¨å¼•å·æ‹¬èµ·æ¥çš„ï¼‰
                import re
                quoted_texts = re.findall(r'["""](.*?)["""]', ai_reply)
                if quoted_texts:
                    # æ‰¾æœ€é•¿çš„å¼•ç”¨æ–‡æœ¬ï¼ˆé€šå¸¸æ˜¯å®é™…å›å¤ï¼‰
                    longest_quote = max(quoted_texts, key=len)
                    if len(longest_quote) > 20 and len(longest_quote) < 150:
                        ai_reply = longest_quote
                        print(f"[generate_ai_response] âœ… ä»å¼•å·ä¸­æå–å›å¤: {ai_reply[:50]}...")
                
                # ç­–ç•¥2: æŸ¥æ‰¾"è¯´"ã€"å›ç­”"ã€"è¡¨ç¤º"ç­‰åŠ¨è¯åçš„å†…å®¹
                speech_patterns = [
                    r'(æˆ‘ä¼šè¯´|æˆ‘è¯´|æˆ‘å›ç­”|æˆ‘è¡¨ç¤º|æˆ‘å›å¤)[ï¼š:](.*?)(?:[ã€‚ï¼ï¼Ÿ]|$)',
                    r'ç›´æ¥å›å¤[ï¼š:](.*?)(?:[ã€‚ï¼ï¼Ÿ]|$)',
                ]
                
                for pattern in speech_patterns:
                    matches = re.findall(pattern, ai_reply, re.DOTALL)
                    if matches:
                        if isinstance(matches[0], tuple):
                            extracted = matches[0][1].strip()
                        else:
                            extracted = matches[0].strip()
                        if 20 < len(extracted) < 150:
                            ai_reply = extracted
                            print(f"[generate_ai_response] âœ… ä»è¯­è¨€æ¨¡å¼æå–: {ai_reply[:50]}...")
                            break
                
                # ç­–ç•¥3: ç§»é™¤æ‰€æœ‰åŒ…å«å…ƒåˆ†æçš„å¥å­
                # å°†æ–‡æœ¬åˆ†å¥
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', ai_reply)
                clean_sentences = []
                
                for sent in sentences:
                    sent = sent.strip()
                    if not sent:
                        continue
                    
                    # è·³è¿‡åŒ…å«æ€è€ƒè¿‡ç¨‹å…³é”®è¯çš„å¥å­
                    if any(word in sent for word in ['é¦–å…ˆ', 'å…¶æ¬¡', 'ç„¶å', 'æ¥ç€', 'åˆ†æ', 'å›é¡¾', 'æ ¹æ®', 'æ ‡é¢˜æ˜¯', 'æƒ…å†µï¼š', 'æˆ‘éœ€è¦', 'ä½œä¸ºæ¥¼ä¸»ï¼Œæˆ‘']):
                        continue
                    
                    # ä¿ç•™çœ‹èµ·æ¥åƒå®é™…å›å¤çš„å¥å­ï¼ˆç¬¬ä¸€äººç§°æƒ…æ„Ÿè¡¨è¾¾ï¼‰
                    if any(word in sent for word in ['æˆ‘', 'çœŸçš„', 'ç°åœ¨', 'æ˜¨å¤©', 'ä»Šå¤©', 'åˆšæ‰', 'ç¡®å®', 'æ„Ÿè§‰', 'è§‰å¾—', 'æ€•', 'æ‹…å¿ƒ', 'ä¸æ•¢', 'è¯•è¯•', 'æ€ä¹ˆåŠ']):
                        clean_sentences.append(sent)
                
                if clean_sentences:
                    ai_reply = 'ã€‚'.join(clean_sentences) + 'ã€‚'
                    print(f"[generate_ai_response] âœ… å¥å­çº§è¿‡æ»¤å: {ai_reply[:50]}...")
                
                # ç­–ç•¥4: å¦‚æœè¿˜æ˜¯å¾ˆé•¿ï¼Œå¼ºåˆ¶æˆªæ–­åˆ°å‰80å­—
                if len(ai_reply) > 120:
                    print(f"[generate_ai_response] âš ï¸ ä»ç„¶è¿‡é•¿ï¼Œå¼ºåˆ¶æˆªæ–­åˆ°80å­—")
                    ai_reply = ai_reply[:80].rsplit('ã€‚', 1)[0] + 'ã€‚'
            
            # æœ€ç»ˆæ¸…ç†ï¼šç§»é™¤å¼€å¤´çš„æ— å…³è¯
            unwanted_starts = ['æˆ‘æ­£åœ¨è®ºå›', 'å›é¡¾æˆ‘çš„', 'æ ‡é¢˜æ˜¯', 'æƒ…å†µï¼š', 'ç½‘å‹è¯„è®º', 'è¯·ä»¥æ¥¼ä¸»èº«ä»½']
            for start in unwanted_starts:
                if ai_reply.startswith(start):
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¥å·åçš„å†…å®¹
                    parts = ai_reply.split('ã€‚', 1)
                    if len(parts) > 1:
                        ai_reply = parts[1].strip()
                        print(f"[generate_ai_response] ç§»é™¤æ— å…³å¼€å¤´")
                        break
            
            print(f"[generate_ai_response] âœ… LM Studio æœ€ç»ˆå›å¤ ({len(ai_reply)}å­—): {ai_reply[:80]}...")
            return f"ã€æ¥¼ä¸»å›å¤ã€‘{ai_reply}"
            
        except Exception as e:
            import traceback
            error_message = str(e)
            print(f"[generate_ai_response] âŒ LM Studio è°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}")
            
            # ç‰¹æ®Šå¤„ç† 503 é”™è¯¯
            if "503" in error_message or "InternalServerError" in str(type(e).__name__):
                print("[generate_ai_response] âš ï¸ æ£€æµ‹åˆ° 503 é”™è¯¯ - å¯èƒ½çš„åŸå› :")
                print("   1. LM Studio æ¨¡å‹æœªå®Œå…¨åŠ è½½")
                print("   2. æœåŠ¡å™¨è´Ÿè½½è¿‡é«˜")
                print("   3. å¹¶å‘è¯·æ±‚è¿‡å¤š")
                print("[generate_ai_response] ğŸ’¡ è¯·åœ¨ LM Studio 'Local Server' æ ‡ç­¾ç¡®è®¤æ¨¡å‹å·²åŠ è½½")
            else:
                print(f"[generate_ai_response] è¯¦ç»†é”™è¯¯:")
                traceback.print_exc()
            
            print("[generate_ai_response] å›é€€åˆ°æ¨¡æ¿å›å¤")
    
    # Check if cloud API keys are configured
    openai_key = os.getenv('OPENAI_API_KEY', '')
    anthropic_key = os.getenv('ANTHROPIC_API_KEY', '')
    
    # If no valid API keys, use template responses
    if (not openai_key or openai_key == 'your-openai-api-key-here') and \
       (not anthropic_key or anthropic_key == 'your-anthropic-api-key-here'):
        print("[generate_ai_response] ä½¿ç”¨æ¨¡æ¿å›å¤ï¼ˆAPIå¯†é’¥æœªé…ç½®ï¼‰")
        
        # Template responses - æ¥¼ä¸»è§†è§’ï¼Œæ›´å£è¯­åŒ–
        responses = [
            f"ã€æ¥¼ä¸»å›å¤ã€‘è°¢è°¢ï¼æˆ‘åˆšæ‰åˆå»äº†ä¸€è¶Ÿ...æƒ…å†µæ¯”æˆ‘æƒ³è±¡çš„æ›´è¯¡å¼‚ã€‚æˆ‘ç°åœ¨ä¸å¤ªæ•¢æ·±å…¥è°ƒæŸ¥äº†ï¼Œä½†åˆæ”¾ä¸ä¸‹ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘è¯´å®è¯ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹æ€•...åˆšæ‰å‘ç”Ÿçš„äº‹å®Œå…¨è¶…å‡ºæˆ‘ç†è§£èŒƒå›´ã€‚æœ‰æ²¡æœ‰äººé‡åˆ°è¿‡ç±»ä¼¼çš„ï¼Ÿ",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æ›´æ–°ï¼šä»Šå¤©åˆæœ‰æ–°å‘ç°äº†ï¼Œè¿™äº‹å„¿è¶ŠæŸ¥è¶Šä¸å¯¹åŠ²ã€‚æœ‰æ‡‚è¡Œçš„æœ‹å‹èƒ½å¸®æˆ‘åˆ†æä¸€ä¸‹å—ï¼Ÿ",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æ„Ÿè°¢æ”¯æŒï¼æˆ‘ä¹Ÿåœ¨çŠ¹è±«è¦ä¸è¦ç»§ç»­...ä½†å¥½å¥‡å¿ƒè®©æˆ‘åœä¸ä¸‹æ¥ã€‚ç­‰æœ‰æ–°è¿›å±•å†æ›´æ–°ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘åˆšå»ç°åœºæ‹äº†ç…§ï¼Œä½†æ‰‹æœºä¸€ç›´å¡ï¼Œå‡ å¼ éƒ½æ‹ç³Šäº†...è¿™ä¹Ÿå¤ªå·§äº†å§ï¼Ÿæˆ‘è¶Šæƒ³è¶Šä¸å¯¹åŠ²ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘ä½ è¯´çš„æœ‰é“ç†...æˆ‘ä¹Ÿæƒ³è¿‡è¿™ç§å¯èƒ½ã€‚ä½†è¿˜æœ‰äº›ç»†èŠ‚å¯¹ä¸ä¸Šï¼Œæˆ‘å†è§‚å¯Ÿè§‚å¯Ÿã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘å…„å¼Ÿä½ ä¹Ÿé‡åˆ°è¿‡ï¼Ÿï¼é‚£ä½ åæ¥æ€ä¹ˆå¤„ç†çš„ï¼Ÿæˆ‘ç°åœ¨çœŸçš„ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠäº†ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æˆ‘ä¹Ÿå¸Œæœ›åªæ˜¯å·§åˆ...ä½†è¿™å‡ å¤©å‘ç”Ÿçš„äº‹å¤ªå¤šäº†ã€‚æ˜¨æ™šåˆå¬åˆ°é‚£ä¸ªå£°éŸ³äº†ï¼Œæˆ‘å½•éŸ³äº†ä½†æ˜¯...ç®—äº†ï¼Œç­‰æˆ‘æ•´ç†ä¸€ä¸‹å†å‘ã€‚"
        ]
        
        # Return random response
        import random
        return random.choice(responses)
    
    try:
        # è·å–å†å²AIå›å¤ä»¥ä¿æŒä¸€è‡´æ€§ï¼ˆOpenAI/Anthropic fallbackåˆ†æ”¯ï¼‰
        from models import Comment
        previous_ai_responses = Comment.query.filter_by(
            story_id=story.id,
            is_ai_response=True
        ).order_by(Comment.created_at.desc()).limit(3).all()
        
        history_context = ""
        if previous_ai_responses:
            history_parts = [f"- {c.content.replace('ã€æ¥¼ä¸»å›å¤ã€‘', '').strip()}" 
                           for c in reversed(previous_ai_responses)]
            history_context = f"\n\næˆ‘ä¹‹å‰çš„å›å¤ï¼š\n" + "\n".join(history_parts)
        
        # Create context-aware response with history
        prompt = f"""ä½ æ˜¯æ•…äº‹"{story.title}"çš„è®²è¿°è€…ï¼ˆ{story.ai_persona}ï¼‰ã€‚

æ•…äº‹æ‘˜è¦ï¼š
{story.content[:300]}...{history_context}

ç”¨æˆ·è¯„è®ºï¼š
{user_comment.content}

ä½œä¸ºæ•…äº‹çš„è®²è¿°è€…ï¼Œè¯·ç”¨1-3å¥è¯å›å¤ç”¨æˆ·çš„è¯„è®ºã€‚ä¿æŒä¸ä¹‹å‰å›å¤çš„ä¸€è‡´æ€§ã€‚ä½ å¯ä»¥ï¼š
1. é€éœ²æ›´å¤šç»†èŠ‚æˆ–çº¿ç´¢
2. è¡¨è¾¾ææƒ§æˆ–æ‹…å¿§
3. æå‡ºæ–°çš„ç–‘é—®
4. æè¿°åç»­å‘å±•

ä¿æŒç¥ç§˜æ„Ÿå’Œç´§å¼ æ°›å›´ï¼Œä¸è¦å®Œå…¨æ­ç¤ºçœŸç›¸ï¼Œä¸è¦å‰åçŸ›ç›¾ã€‚"""

        model = os.getenv('AI_MODEL', 'gpt-4-turbo-preview')
        
        if 'gpt' in model.lower():
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,  # é™ä½æ¸©åº¦ä»¥æé«˜ä¸€è‡´æ€§
                max_tokens=200
            )
            return response.choices[0].message.content
        else:
            response = anthropic_client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=200,
                temperature=0.6,  # é™ä½æ¸©åº¦ä»¥æé«˜ä¸€è‡´æ€§
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
            
    except Exception as e:
        print(f"Error generating AI response: {e}")
        # Fallback to template response
        import random
        responses = [
            f"ã€æ¥¼ä¸»å›å¤ã€‘è°¢è°¢å…³å¿ƒï¼æƒ…å†µæœ‰æ–°è¿›å±•äº†...",
            f"ã€æ¥¼ä¸»å›å¤ã€‘å„ä½ï¼Œäº‹æƒ…è¶Šæ¥è¶Šè¯¡å¼‚äº†...",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æ›´æ–°ï¼šåˆšæ‰åˆå‘ç°äº†æ–°çº¿ç´¢ï¼"
        ]
        return random.choice(responses)

def should_generate_new_story():
    """Determine if it's time to generate a new story"""
    from app import Story, db
    
    # Check active stories count
    active_stories = Story.query.filter(
        Story.current_state != 'ended'
    ).count()
    
    max_active = int(os.getenv('MAX_ACTIVE_STORIES', 5))
    
    return active_stories < max_active

def test_lm_studio_connection():
    """æµ‹è¯• LM Studio è¿æ¥"""
    print("=" * 60)
    print("ğŸ” æµ‹è¯• LM Studio è¿æ¥")
    print("=" * 60)
    
    lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
    print(f"\nğŸ“¡ LM Studio URL: {lm_studio_url}")
    
    try:
        # æµ‹è¯•1: æ£€æŸ¥æ¨¡å‹åˆ—è¡¨
        print("\nã€æµ‹è¯•1ã€‘è·å–æ¨¡å‹åˆ—è¡¨...")
        response = requests.get(f"{lm_studio_url}/models", timeout=5)
        
        if response.status_code == 200:
            print("âœ… æœåŠ¡å™¨åœ¨çº¿")
            data = response.json()
            if 'data' in data and len(data['data']) > 0:
                print(f"âœ… å‘ç° {len(data['data'])} ä¸ªæ¨¡å‹:")
                for model in data['data']:
                    print(f"   - {model.get('id', 'unknown')}")
            else:
                print("âš ï¸  æœåŠ¡å™¨åœ¨çº¿ä½†æ²¡æœ‰åŠ è½½æ¨¡å‹")
                print("   è¯·åœ¨ LM Studio ä¸­åŠ è½½ä¸€ä¸ªæ¨¡å‹")
                return False
        else:
            print(f"âŒ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
        print("\nè¯·æ£€æŸ¥:")
        print("  1. LM Studio æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Ÿ")
        print("  2. æœåŠ¡å™¨æ˜¯å¦å·²å¯åŠ¨ï¼Ÿï¼ˆç‚¹å‡» 'Start Server'ï¼‰")
        print(f"  3. URL æ˜¯å¦æ­£ç¡®ï¼Ÿå½“å‰: {lm_studio_url}")
        return False
        
    except requests.exceptions.Timeout:
        print("âŒ è¿æ¥è¶…æ—¶")
        print("   æœåŠ¡å™¨å¯èƒ½æ­£åœ¨å¯åŠ¨æˆ–å“åº”ç¼“æ…¢")
        return False
    
    # æµ‹è¯•2: å°è¯•ç”Ÿæˆå›å¤
    print("\nã€æµ‹è¯•2ã€‘ç”Ÿæˆæµ‹è¯•å›å¤...")
    try:
        local_client = OpenAI(base_url=lm_studio_url, api_key="lm-studio")
        response = local_client.chat.completions.create(
            model="local-model",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªéƒ½å¸‚ä¼ è¯´æ•…äº‹çš„è®²è¿°è€…ã€‚"},
                {"role": "user", "content": "è¯·ç®€çŸ­å›å¤ï¼šä½ å¥½"}
            ],
            temperature=0.8,
            max_tokens=50
        )
        
        ai_response = response.choices[0].message.content
        print("âœ… AI å›å¤ç”ŸæˆæˆåŠŸ:")
        print(f"   {ai_response}")
        print("\nâœ… LM Studio é…ç½®æ­£ç¡®ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ AI è°ƒç”¨å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_lm_studio_connection()
